{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":14770017,"datasetId":9440924,"databundleVersionId":15622016},{"sourceType":"datasetVersion","sourceId":14769758,"datasetId":9440749,"databundleVersionId":15621745},{"sourceType":"datasetVersion","sourceId":14771302,"datasetId":9441838,"databundleVersionId":15623418}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%file model.py\n\nfrom accelerate import Accelerator\naccelerator = Accelerator()   # no mixed_precision\n\nimport os\nimport bisect\nfrom PIL import Image, UnidentifiedImageError\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\nfrom torchvision.transforms import v2 as T\nfrom tqdm import tqdm\n\n# -----------------------------\n# Dataset\n# -----------------------------\n\n\n\ndef save_last_checkpoint(epoch, model, optimizer, best_val_loss, path=\"last_checkpoint.pth\"):\n    torch.save({\n        \"epoch\": epoch,\n        \"model_state_dict\": model.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n        \"best_val_loss\": best_val_loss,\n    }, path)\n\n\ndef load_checkpoint(path, model, optimizer, device):\n    if os.path.exists(path):\n        print(\"ðŸ”„ Found checkpoint. Resuming training...\")\n        checkpoint = torch.load(path, map_location=device)\n\n        model.load_state_dict(checkpoint[\"model_state_dict\"])\n        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n\n        start_epoch = checkpoint[\"epoch\"] + 1\n        best_val_loss = checkpoint[\"best_val_loss\"]\n\n        print(f\"âœ… Resumed from epoch {start_epoch}\")\n        return start_epoch, best_val_loss\n    else:\n        print(\"ðŸš€ No checkpoint found. Starting fresh.\")\n        return 0, float(\"inf\")\n\n\n\n\n\n\nclass DrowsySequenceDataset(Dataset):\n    def __init__(self, root_dir, seq_len=16, transform=None):\n        self.seq_len = seq_len\n        self.transform = transform\n\n        self.video_info = []\n        self.cumulative_windows = []\n\n        total_windows = 0\n        print(\"[Dataset] Indexing dataset...\")\n\n        for subject in os.listdir(root_dir):\n            subject_path = os.path.join(root_dir, subject)\n            if not os.path.isdir(subject_path):\n                continue\n\n            for scenario in os.listdir(subject_path):\n                scenario_path = os.path.join(subject_path, scenario)\n                if not os.path.isdir(scenario_path):\n                    continue\n\n                frame_files = sorted([\n                    f for f in os.listdir(scenario_path)\n                    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n                ])\n\n                num_frames = len(frame_files)\n                if num_frames < self.seq_len:\n                    continue\n\n                num_windows = num_frames - self.seq_len + 1\n                total_windows += num_windows\n                self.video_info.append((scenario_path, frame_files, num_windows))\n                self.cumulative_windows.append(total_windows)\n\n        self.total_windows = total_windows\n        print(f\"[Dataset] Total scenarios: {len(self.video_info)}\")\n        print(f\"[Dataset] Total sequences: {self.total_windows}\")\n\n    def __len__(self):\n        return self.total_windows\n\n    def __getitem__(self, idx):\n        video_idx = bisect.bisect_right(self.cumulative_windows, idx)\n\n        window_start = idx if video_idx == 0 else idx - self.cumulative_windows[video_idx - 1]\n        video_path, frame_files, _ = self.video_info[video_idx]\n\n        images = []\n        frame_slice = frame_files[window_start:window_start + self.seq_len]\n        frame_labels = []\n\n        for fname in frame_slice:\n            img_path = os.path.join(video_path, fname)\n            try:\n                img = Image.open(img_path).convert(\"L\")  # Grayscale\n                if self.transform:\n                    img = self.transform(img)\n                if isinstance(img, torch.Tensor) and img.ndim == 2:\n                    img = img.unsqueeze(0)\n                images.append(img)\n\n                # Label extraction: last underscore before extension\n                label = int(fname.rsplit(\"_\", 1)[-1].split(\".\")[0])\n                frame_labels.append(label)\n\n            except (UnidentifiedImageError, OSError):\n                images.append(torch.zeros(1, 224, 224))\n                frame_labels.append(0)\n\n        images = torch.stack(images)  # (T, C, H, W)\n        # Aggregate labels: Drowsy if any frame is drowsy\n        label = int(any(frame_labels))\n\n        return images, torch.tensor(label, dtype=torch.long)\n\n# -----------------------------\n# CNN Encoder (MobileNetV3 Small)\n# -----------------------------\nclass CNNEncoder(nn.Module):\n    def __init__(self, feature_dim=512, pretrained=True):\n        super().__init__()\n        weights = MobileNet_V3_Small_Weights.DEFAULT\n        mobilenet = mobilenet_v3_small(weights=weights)\n\n        # Replace first conv for 1-channel input\n        old_conv = mobilenet.features[0][0]\n        mobilenet.features[0][0] = nn.Conv2d(\n            in_channels=1,\n            out_channels=old_conv.out_channels,\n            kernel_size=old_conv.kernel_size,\n            stride=old_conv.stride,\n            padding=old_conv.padding,\n            bias=False\n        )\n        with torch.no_grad():\n            mobilenet.features[0][0].weight.copy_(old_conv.weight.mean(dim=1, keepdim=True))\n\n        self.features = mobilenet.features\n        self.pool = nn.AdaptiveAvgPool2d((1,1))\n        self.fc = nn.Linear(576, feature_dim)\n\n        # Freeze all MobileNet weights (can unfreeze last layers if needed)\n        for param in self.features.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.pool(x)\n        x = x.flatten(1)\n        x = self.fc(x)\n        return x  # (B*T, feature_dim)\n\n# -----------------------------\n# Causal TCN Block\n# -----------------------------\nclass CausalTemporalConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=1):\n        super().__init__()\n        self.padding = (kernel_size - 1) * dilation\n\n        self.conv = nn.Conv1d(\n            in_channels, out_channels, kernel_size,\n            padding=self.padding, dilation=dilation\n        )\n        self.norm = nn.GroupNorm(num_groups=8, num_channels=out_channels)\n        self.relu = nn.GELU()\n        self.residual = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n\n    def forward(self, x):\n        out = self.conv(x)\n        if self.padding > 0:\n            out = out[:, :, :-self.padding]  # causal trimming\n        out = self.norm(out)\n        out = self.relu(out)\n        return out + self.residual(x)\n\n# -----------------------------\n# Full CNN + TCN Model\n# -----------------------------\nclass CNNTemporalConv(nn.Module):\n    def __init__(self, feature_dim=512):\n        super().__init__()\n        self.encoder = CNNEncoder(feature_dim)\n        self.tcn = nn.Sequential(\n            CausalTemporalConvBlock(feature_dim, 256, kernel_size=3, dilation=1),\n            CausalTemporalConvBlock(256, 256, kernel_size=3, dilation=2),\n            CausalTemporalConvBlock(256, 128, kernel_size=3, dilation=4),\n        )\n        self.classifier = nn.Linear(128, 1)\n\n    def forward(self, x):\n        B, T, C, H, W = x.shape\n        x = x.view(B*T, C, H, W)\n        features = self.encoder(x)           # (B*T, F)\n        features = features.view(B, T, -1)   # (B, T, F)\n        features = features.transpose(1, 2)  # (B, F, T)\n        tcn_out = self.tcn(features)         # (B, 128, T)\n        last_feature = tcn_out[:, :, -1]     # (B, 128)\n        logits = self.classifier(last_feature)\n        return logits.squeeze(1)             # (B,)\n\n# -----------------------------\n# Transforms\n# -----------------------------\ntransform = T.Compose([\n    T.ToImage(),                        # PIL â†’ Tensor\n    T.ToDtype(torch.float32, scale=1/255),\n    T.Normalize(mean=[0.5], std=[0.5])  # Grayscale normalization\n])\n\n# -----------------------------\n# Datasets & Loaders\n# -----------------------------\n\n\n# train_ds1 = DrowsySequenceDataset(\"/root/.cache/kagglehub/datasets/manith04/ddd-processed-1-training-frames-type-1/versions/1\", transform=transform)\n# train_ds2 = DrowsySequenceDataset(\"/root/.cache/kagglehub/datasets/manith04/ddd-processed-2-training-frames-type-1/versions/1\", transform=transform)\n# val_ds = DrowsySequenceDataset(\"/root/.cache/kagglehub/datasets/manith04/ddd-processed-validation-frames-type-1/versions/1\", transform=transform)\n\ntrain_ds1 = DrowsySequenceDataset(\"/kaggle/input/datasets/manith04/ddd-processed-1-training-frames-type-1\", transform=transform)\ntrain_ds2 = DrowsySequenceDataset(\"/kaggle/input/datasets/manith04/ddd-processed-2-training-frames-type-1\", transform=transform)\nval_ds = DrowsySequenceDataset(\"/kaggle/input/datasets/manith04/ddd-processed-validation-frames-type-1\", transform=transform)\n\n\ntrain_dataset = ConcatDataset([train_ds1, train_ds2])\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n\n# -----------------------------\n# Device, Model, Optimizer\n# -----------------------------\nmodel = CNNTemporalConv()\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.AdamW(model.parameters(), lr=1e-4)\n\n\nepochs = 51\ncheckpoint_path = \"last_checkpoint.pth\"\nbest_model_path = \"best_model.pth\"\n\n\n\nmodel, optimizer, train_loader, val_loader = accelerator.prepare(model, optimizer, train_loader, val_loader)\n\nif os.path.exists(checkpoint_path):\n    start_epoch, best_val_loss = load_checkpoint(checkpoint_path, model, optimizer, accelerator.device)\nelse:\n    start_epoch = 0\n    best_val_loss = float(\"inf\")\n\n\n\nfor epoch in range(start_epoch, epochs):\n    print(\"\\n\" + \"=\"*60)\n    print(f\"Epoch {epoch+1}/{epochs}\")\n    print(\"=\"*60)\n\n    model.train()\n    train_loss = 0\n    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n\n    for frames, labels in progress_bar:\n        labels = labels.float()\n        outputs = model(frames)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        accelerator.backward(loss)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n        train_loss += loss.item()\n        progress_bar.set_postfix({\"Batch Loss\": loss.item()})\n\n    avg_train_loss = train_loss / len(train_loader)\n\n    # --------- VALIDATION ----------\n    model.eval()\n    val_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for frames, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            labels = labels.float()\n            outputs = model(frames)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            preds = (torch.sigmoid(outputs) > 0.5).int()\n            correct += (preds == labels.int()).sum().item()\n            total += labels.numel()\n\n    avg_val_loss = val_loss / len(val_loader)\n    val_acc = correct / total\n\n    # --------- SUMMARY ----------\n    print(f\"Train Loss : {avg_train_loss:.4f}\")\n    print(f\"Val Loss   : {avg_val_loss:.4f}\")\n    print(f\"Val Acc    : {val_acc:.4f}\")\n\n    # with open(\"experiment.txt\", \"a\") as file:\n    #     file.write(avg_train_loss, )\n        \n\n    # --------- SAVE BEST MODEL ----------\n    if accelerator.is_main_process:\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            unwrapped_model = accelerator.unwrap_model(model)\n            torch.save(unwrapped_model.state_dict(), best_model_path)\n            print(\"â­ Best model updated!\")\n\n        # Always save last checkpoint\n        save_last_checkpoint(epoch, model, optimizer, best_val_loss, checkpoint_path)\n\nprint(\"\\nðŸŽ‰ Training Complete.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-21T06:19:48.066901Z","iopub.execute_input":"2026-02-21T06:19:48.067544Z","iopub.status.idle":"2026-02-21T06:19:48.081970Z","shell.execute_reply.started":"2026-02-21T06:19:48.067509Z","shell.execute_reply":"2026-02-21T06:19:48.081286Z"}},"outputs":[{"name":"stdout","text":"Overwriting model.py\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!accelerate launch model.py --no-processes=2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:16:21.835169Z","iopub.execute_input":"2026-02-20T09:16:21.835883Z"}},"outputs":[{"name":"stdout","text":"The following values were not passed to `accelerate launch` and had defaults used instead:\n\t`--num_processes` was set to a value of `2`\n\t\tMore than one GPU was found, enabling multi-GPU training.\n\t\tIf this was unintended please pass in `--num_processes=1`.\n\t`--num_machines` was set to a value of `1`\n\t`--mixed_precision` was set to a value of `'no'`\n\t`--dynamo_backend` was set to a value of `'no'`\nTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n[Dataset] Indexing dataset...\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 49\n[Dataset] Total sequences: 394956\n[Dataset] Total scenarios: 49\n[Dataset] Total sequences: 394956[Dataset] Indexing dataset...\n\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 40\n[Dataset] Total sequences: 326956\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 40\n[Dataset] Total sequences: 326956\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 20\n[Dataset] Total sequences: 172959\n[Dataset] Total scenarios: 20\n[Dataset] Total sequences: 172959\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.83M/9.83M [00:00<00:00, 92.2MB/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.83M/9.83M [00:00<00:00, 83.9MB/s]\n\n============================================================\nEpoch 1/51\n\n========================================================================================================================\n\nEpoch 1/51\n============================================================\nTrain Loss : 0.1704                                                             \nVal Loss   : 1.2750\nVal Acc    : 0.6545\nâ­ Best model updated!\n\n============================================================\nEpoch 2/51\n============================================================\nTrain Loss : 0.1708                                                             \nVal Loss   : 1.2507\nVal Acc    : 0.6651\n\n============================================================\nEpoch 2/51\n============================================================\nTraining:   2%|â–          | 56/2820 [02:52<1:42:08,  2.22s/it, Batch Loss=0.106]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!accelerate launch model.py --no-processes=2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T15:17:58.966871Z","iopub.execute_input":"2026-02-20T15:17:58.967221Z"}},"outputs":[{"name":"stdout","text":"The following values were not passed to `accelerate launch` and had defaults used instead:\n\t`--num_processes` was set to a value of `2`\n\t\tMore than one GPU was found, enabling multi-GPU training.\n\t\tIf this was unintended please pass in `--num_processes=1`.\n\t`--num_machines` was set to a value of `1`\n\t`--mixed_precision` was set to a value of `'no'`\n\t`--dynamo_backend` was set to a value of `'no'`\nTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n[Dataset] Indexing dataset...[Dataset] Indexing dataset...\n\n[Dataset] Total scenarios: 49\n[Dataset] Total sequences: 394956\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 49\n[Dataset] Total sequences: 394956\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 40\n[Dataset] Total scenarios: 40[Dataset] Total sequences: 326956\n\n[Dataset] Total sequences: 326956\n[Dataset] Indexing dataset...\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 20\n[Dataset] Total sequences: 172959\n[Dataset] Total scenarios: 20\n[Dataset] Total sequences: 172959\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.83M/9.83M [00:00<00:00, 86.0MB/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.83M/9.83M [00:00<00:00, 85.1MB/s]\nðŸ”„ Found checkpoint. Resuming training...\nðŸ”„ Found checkpoint. Resuming training...\nâœ… Resumed from epoch 1\n\n============================================================\nEpoch 2/51\n============================================================\nTraining:   0%|                                        | 0/2820 [00:00<?, ?it/s]âœ… Resumed from epoch 1\n\n============================================================\nEpoch 2/51\n============================================================\nTraining:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2644/2820 [2:06:59<06:48,  2.32s/it, Batch Loss=0.0595]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!accelerate launch model.py --no-processes=2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T06:19:51.102457Z","iopub.execute_input":"2026-02-21T06:19:51.102775Z"}},"outputs":[{"name":"stdout","text":"The following values were not passed to `accelerate launch` and had defaults used instead:\n\t`--num_processes` was set to a value of `2`\n\t\tMore than one GPU was found, enabling multi-GPU training.\n\t\tIf this was unintended please pass in `--num_processes=1`.\n\t`--num_machines` was set to a value of `1`\n\t`--mixed_precision` was set to a value of `'no'`\n\t`--dynamo_backend` was set to a value of `'no'`\nTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n[Dataset] Indexing dataset...\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 49\n[Dataset] Total sequences: 394956[Dataset] Total scenarios: 49\n\n[Dataset] Total sequences: 394956\n[Dataset] Indexing dataset...[Dataset] Indexing dataset...\n\n[Dataset] Total scenarios: 40[Dataset] Total scenarios: 40\n\n[Dataset] Total sequences: 326956[Dataset] Total sequences: 326956\n\n[Dataset] Indexing dataset...[Dataset] Indexing dataset...\n\n[Dataset] Total scenarios: 20\n[Dataset] Total sequences: 172959\n[Dataset] Total scenarios: 20\n[Dataset] Total sequences: 172959\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.83M/9.83M [00:00<00:00, 88.1MB/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.83M/9.83M [00:00<00:00, 93.6MB/s]\nðŸ”„ Found checkpoint. Resuming training...\nðŸ”„ Found checkpoint. Resuming training...\nâœ… Resumed from epoch 3\n\n============================================================\nEpoch 4/51\n============================================================\nTraining:   0%|                                        | 0/2820 [00:00<?, ?it/s]âœ… Resumed from epoch 3\n\n============================================================\nEpoch 4/51\n============================================================\nTraining:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2214/2820 [1:40:47<23:45,  2.35s/it, Batch Loss=0.015]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!accelerate launch model.py --no-processes=2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T13:16:01.330445Z","iopub.execute_input":"2026-02-21T13:16:01.330736Z","execution_failed":"2026-02-22T03:55:20.794Z"}},"outputs":[{"name":"stdout","text":"The following values were not passed to `accelerate launch` and had defaults used instead:\n\t`--num_processes` was set to a value of `2`\n\t\tMore than one GPU was found, enabling multi-GPU training.\n\t\tIf this was unintended please pass in `--num_processes=1`.\n\t`--num_machines` was set to a value of `1`\n\t`--mixed_precision` was set to a value of `'no'`\n\t`--dynamo_backend` was set to a value of `'no'`\nTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n[Dataset] Indexing dataset...\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 49\n[Dataset] Total sequences: 394956\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 49\n[Dataset] Total sequences: 394956\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 40\n[Dataset] Total sequences: 326956\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 40\n[Dataset] Total sequences: 326956\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 20\n[Dataset] Total sequences: 172959\n[Dataset] Total scenarios: 20\n[Dataset] Total sequences: 172959\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.83M/9.83M [00:00<00:00, 92.1MB/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.83M/9.83M [00:00<00:00, 83.2MB/s]\nðŸ”„ Found checkpoint. Resuming training...\nðŸ”„ Found checkpoint. Resuming training...\nâœ… Resumed from epoch 3\n\n============================================================\nEpoch 4/51\n============================================================\nâœ… Resumed from epoch 3\n\n============================================================\nEpoch 4/51\n============================================================\nValidation:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 305/676 [12:20<13:00,  2.10s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!accelerate launch model.py --no-processes=2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T04:35:36.287673Z","iopub.execute_input":"2026-02-22T04:35:36.288015Z","execution_failed":"2026-02-22T06:36:35.019Z"}},"outputs":[{"name":"stdout","text":"The following values were not passed to `accelerate launch` and had defaults used instead:\n\t`--num_processes` was set to a value of `2`\n\t\tMore than one GPU was found, enabling multi-GPU training.\n\t\tIf this was unintended please pass in `--num_processes=1`.\n\t`--num_machines` was set to a value of `1`\n\t`--mixed_precision` was set to a value of `'no'`\n\t`--dynamo_backend` was set to a value of `'no'`\nTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n[Dataset] Indexing dataset...\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 49\n[Dataset] Total sequences: 394956\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 49\n[Dataset] Total sequences: 394956\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 40\n[Dataset] Total sequences: 326956\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 40\n[Dataset] Total sequences: 326956\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 20\n[Dataset] Total sequences: 172959\n[Dataset] Total scenarios: 20\n[Dataset] Total sequences: 172959\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.83M/9.83M [00:00<00:00, 107MB/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.83M/9.83M [00:00<00:00, 93.9MB/s]\nðŸ”„ Found checkpoint. Resuming training...\nðŸ”„ Found checkpoint. Resuming training...\nâœ… Resumed from epoch 4\n\n============================================================\nEpoch 5/51\n============================================================\nâœ… Resumed from epoch 4\n\n============================================================\nEpoch 5/51\n============================================================\nTraining:  13%|â–ˆâ–       | 359/2820 [20:39<1:04:59,  1.58s/it, Batch Loss=0.0578]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!accelerate launch model.py --no-processes=2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T07:24:48.939691Z","iopub.execute_input":"2026-02-22T07:24:48.939948Z","execution_failed":"2026-02-22T19:24:31.543Z"}},"outputs":[{"name":"stdout","text":"The following values were not passed to `accelerate launch` and had defaults used instead:\n\t`--num_processes` was set to a value of `2`\n\t\tMore than one GPU was found, enabling multi-GPU training.\n\t\tIf this was unintended please pass in `--num_processes=1`.\n\t`--num_machines` was set to a value of `1`\n\t`--mixed_precision` was set to a value of `'no'`\n\t`--dynamo_backend` was set to a value of `'no'`\nTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n[Dataset] Indexing dataset...\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 49\n[Dataset] Total sequences: 394956\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 49\n[Dataset] Total sequences: 394956\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 40[Dataset] Total scenarios: 40\n[Dataset] Total sequences: 326956\n\n[Dataset] Total sequences: 326956\n[Dataset] Indexing dataset...\n[Dataset] Indexing dataset...\n[Dataset] Total scenarios: 20\n[Dataset] Total sequences: 172959\n[Dataset] Total scenarios: 20\n[Dataset] Total sequences: 172959\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.83M/9.83M [00:00<00:00, 99.2MB/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.83M/9.83M [00:00<00:00, 87.1MB/s]\nðŸ”„ Found checkpoint. Resuming training...\nðŸ”„ Found checkpoint. Resuming training...\nâœ… Resumed from epoch 4\n\n============================================================\nEpoch 5/51\n============================================================\nTraining:   0%|                                        | 0/2820 [00:00<?, ?it/s]âœ… Resumed from epoch 4\n\n============================================================\nEpoch 5/51\n============================================================\nTrain Loss : 0.0343                                                             \nVal Loss   : 1.7126\nVal Acc    : 0.6456\n\n============================================================\nEpoch 6/51\n============================================================\nTrain Loss : 0.0347                                                             \nVal Loss   : 1.7622\nVal Acc    : 0.6240\n\n============================================================\nEpoch 6/51\n============================================================\nTrain Loss : 0.0306                                                             \nVal Loss   : 2.2118\nVal Acc    : 0.6161\n\n============================================================\nEpoch 7/51\n============================================================\nTrain Loss : 0.0299                                                             \nVal Loss   : 2.1438\nVal Acc    : 0.6268\n\n============================================================\nEpoch 7/51\n============================================================\nTrain Loss : 0.0274                                                             \nVal Loss   : 2.2148\nVal Acc    : 0.6527\n\n============================================================\nEpoch 8/51\n============================================================\nTrain Loss : 0.0272                                                             \nVal Loss   : 2.2471\nVal Acc    : 0.6350\n\n============================================================\nEpoch 8/51\n============================================================\nTrain Loss : 0.0237                                                             \nVal Loss   : 2.1786\nVal Acc    : 0.6546\n\n============================================================\nEpoch 9/51\n============================================================\nTrain Loss : 0.0235                                                             \nVal Loss   : 2.2897\nVal Acc    : 0.6304\n\n============================================================\nEpoch 9/51\n============================================================\nTrain Loss : 0.0222                                                             \nVal Loss   : 1.9498\nVal Acc    : 0.6463\n\n============================================================\nEpoch 10/51\n============================================================\nTrain Loss : 0.0215                                                             \nVal Loss   : 2.0423\nVal Acc    : 0.6374\n\n============================================================\nEpoch 10/51\n============================================================\nTraining:  15%|â–ˆâ–Ž       | 419/2820 [18:26<1:35:27,  2.39s/it, Batch Loss=0.0118]","output_type":"stream"}],"execution_count":null}]}