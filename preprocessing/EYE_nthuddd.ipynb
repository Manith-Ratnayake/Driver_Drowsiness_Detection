{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7VTRq9gFtkF",
        "outputId": "a5f9c35f-5e53-4686-adcc-c72501de9967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.3).\n",
            "/root/.cache/kagglehub/datasets/manith04/ddd-processed-1-training-frames-type-1/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"manith04/ddd-processed-1-training-frames-type-1\")\n",
        "#dddeeee  #ddewewewee  #manith04/gdgdfhfg\n",
        "print(path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list -s \"manith04\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-DO7k3nW7bF",
        "outputId": "209547e5-c5a2-4f19-97e7-09114592c616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                     title                                size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------  ----------------------------  -----------  --------------------------  -------------  ---------  ---------------  \n",
            "manith04/slt-mobitel                    SLT_Mobitel                          4036  2025-05-22 11:24:53.007000              3          0  0.25             \n",
            "manith04/abcdefg                        abcdefg                             94485  2025-05-23 08:48:36.640000              0          0  0.25             \n",
            "manith04/genai-flux                     genAI_flux                         242974  2025-09-25 21:39:03.127000              0          0  0.25             \n",
            "manith04/aigodmanith                    AIGODMANITH                         48456  2025-08-28 17:13:46.787000              0          0  0.25             \n",
            "manith04/llm-finetune-manith            LLM_Finetune_Manith               4959700  2025-06-05 05:13:09.347000              1          0  0.25             \n",
            "manith04/visionnetworkgemmini1          VisionNetworkGemmini1             8653826  2025-08-01 09:13:34.737000              1          0  0.25             \n",
            "manith04/manith-kitty-object-detection  kitty_object_detection        12351650815  2026-01-11 03:38:40.497000              0          0  0.25             \n",
            "manith04/manith-kitty                   manith-kitty                        17565  2026-01-11 03:43:15.690000              0          0  0.25             \n",
            "manith04/kitty-scripts                  kitty_scripts                        1435  2026-01-11 19:15:14.133000              0          0  0.25             \n",
            "manith04/manith-kitty-object-tracking   manith-kitty-object-tracking  15542276170  2026-01-11 07:26:57.910000              0          0  0.25             \n",
            "manith04/manith-cityscapes              manith-cityscapes               251411554  2026-01-11 12:18:22.940000              0          0  0.25             \n",
            "manith04/ddd-evaluation-code            ddd-evaluation-code                  1304  2026-02-09 08:19:12.617000              0          0  0.25             \n",
            "manith04/rt-image                       RT_Image                        945260932  2025-12-14 13:18:37.033000              3          0  0.25             \n",
            "manith04/raw-ddd                        nthuddd_raw_train_1            1584972727  2026-01-21 08:36:03.087000              2          0  0.25             \n",
            "manith04/dddeeee                        nthuddd_training_1             3253271203  2026-01-22 06:33:38.977000             11          0  0.25             \n",
            "manith04/ddewewewee                     nthuddd_training_2             2695662790  2026-01-22 08:07:13.807000              8          0  0.25             \n",
            "manith04/gdgdfhfg                       nthuddd_validation              247619240  2026-01-22 08:59:27.713000              5          0  0.25             \n",
            "manith04/ky87retdgfu7t                  nthuddd_testing                1144495468  2026-01-22 08:59:32.803000              9          0  0.25             \n",
            "manith04/ddd-testing-frames             Testing frames                31332816406  2026-02-08 16:44:49.557000              2          0  0.25             \n",
            "manith04/ddd-train                      ddd_train                            9807  2025-09-22 02:50:57.457000              0          0  0.125            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbaTrgwFM25j"
      },
      "outputs": [],
      "source": [
        "!echo KAGGLE_API_TOKEN=KGAT_28e717b9ccd1d5f6908afdf6559d8cb4 | touch ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSpQ0XdvNI51"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "mkdir -p ~/.kaggle\n",
        "echo '{\"username\":\"manith04\",\"key\":\"KGAT_28e717b9ccd1d5f6908afdf6559d8cb4\"}' > ~/.kaggle/kaggle.json\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "#!kaggle datasets download -d manith04/manith-kitty-dataset -p ./data --unzip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJQrK0HVS0z_",
        "outputId": "95668314-3a6f-4911-80cb-58baa663bbc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                             title                                                   size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------  ------------------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
            "saidaminsaidaxmadov/chocolate-sales                             Chocolate Sales                                       468320  2026-01-04 14:23:35.490000          17213        307  1.0              \n",
            "aliiihussain/amazon-sales-dataset                               Amazon_Sales_Dataset                                 1297759  2026-02-01 11:37:12.353000           3568         66  1.0              \n",
            "ayeshasiddiqa123/student-perfirmance                            Student Academic Performance Dataset.                  96178  2026-01-06 12:08:32.540000           5749        108  1.0              \n",
            "emirhanakku/ai-model-failure-and-recovery-dataset-20182026      AI Model Failure & Recovery Dataset 2018–2026         704374  2026-02-08 18:22:02.007000            402         24  1.0              \n",
            "hassanjameelahmed/price-of-healthy-diet-clean                   Global Healthy Diet Cost Analysis (2017–2024)          14103  2026-02-05 07:18:40.347000            617         22  1.0              \n",
            "sonalshinde123/work-from-home-employee-burnout-dataset          Work From Home Employee Burnout Dataset                27962  2026-01-31 03:28:22.227000           1936         45  1.0              \n",
            "ayeshaimran1619/foodpanda-data-analysis                         Foodpanda Data Analysis                               196335  2026-02-06 07:41:08.650000            426         27  1.0              \n",
            "vishardmehta/gold-price-forecasting-dataset                     Gold Price Forecasting Dataset                        138149  2026-02-02 10:27:21.830000           1581         30  1.0              \n",
            "rockyt07/social-media-user-analysis                             Social Media User Analysis                         247842357  2026-01-14 02:28:41.970000           9207        174  1.0              \n",
            "hassanjameelahmed/store-sales                                   Retail Store Sales                                     66677  2026-02-04 06:31:47.217000            983         32  1.0              \n",
            "dhrubangtalukdar/mercedes-global-car-sales-2020-2025            Mercedes Global Car Sales 2020-2025                 93377423  2026-02-02 15:27:26.227000           1276         34  1.0              \n",
            "ibrahimshahrukh/tesla-stock-price-historical-dataset-2010-2025  Tesla Stock Price Historical Dataset (2010-2025)      137925  2026-02-07 02:32:35.947000            491         26  1.0              \n",
            "ayeshaimran1619/student-academic-stress-level                   Student Academic Stress Level                           2104  2026-01-18 09:19:44.433000           1189         27  1.0              \n",
            "sanaijlalshahrukh/gold-price-analysis-10-year-historical-data   Gold Price analysis 10-Year Historical Data            41715  2026-02-05 03:45:30.177000           1000         27  1.0              \n",
            "vishardmehta/indian-engineering-college-placement-dataset       Indian Engineering College Placement Dataset          137603  2026-01-24 15:23:40.150000           2862         58  1.0              \n",
            "wardabilal/customer-shopping-behaviour-analysis                 Customer Shopping Behaviour Analysis                   67263  2026-01-25 05:50:56.253000           1643         32  1.0              \n",
            "sadiajavedd/social-media-user-activity-dataset                  Social Media User Activity Dataset                 123931685  2026-02-02 15:27:56.120000           1239         32  0.9411765        \n",
            "amineipad/loan-approval-dataset                                 Loan Approval Dataset                                  16105  2026-01-11 10:46:28.780000            886         24  1.0              \n",
            "hassanjameelahmed/olympic-dataset                               Olympic Games Dataset                                 614901  2026-02-03 06:32:44.130000           1046         27  1.0              \n",
            "thedrzee/spotify-long-hits-dataset-2014-2024                    Spotify Long Hits Dataset_(2014-2024)                  39137  2026-02-01 13:07:24.790000            811         60  0.88235295       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv python install 3.10\n",
        "!export PATH=\"/root/.local/bin:$PATH\"\n",
        "!which python3.10\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WcCO1zFQDeJ",
        "outputId": "2165bf0a-5d8c-4678-b644-3a4eb332f550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10 is already installed\n",
            "/usr/bin/python3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "uv pip install --python python3.10 mediapipe==0.10.9 opencv-python tqdm matplotlib -q\n"
      ],
      "metadata": {
        "id": "vuG3JzYqQIjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file ex.py\n",
        "import os\n",
        "os.environ[\"MPLBACKEND\"] = \"Agg\"\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Eye landmark indices (MediaPipe Face Mesh)\n",
        "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
        "\n",
        "TARGET_SIZE = 224\n",
        "MARGIN = 0.25  # expand eye box slightly\n",
        "\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "\n",
        "def crop_eye(image, landmarks, eye_indices):\n",
        "    h, w, _ = image.shape\n",
        "\n",
        "    pts = np.array([\n",
        "        (int(landmarks[i].x * w), int(landmarks[i].y * h))\n",
        "        for i in eye_indices\n",
        "    ])\n",
        "\n",
        "    x_min, y_min = pts.min(axis=0)\n",
        "    x_max, y_max = pts.max(axis=0)\n",
        "\n",
        "    # Expand bounding box\n",
        "    bw = x_max - x_min\n",
        "    bh = y_max - y_min\n",
        "    cx = (x_min + x_max) // 2\n",
        "    cy = (y_min + y_max) // 2\n",
        "\n",
        "    size = int(max(bw, bh) * (1 + MARGIN))\n",
        "\n",
        "    x1 = max(cx - size // 2, 0)\n",
        "    y1 = max(cy - size // 2, 0)\n",
        "    x2 = min(cx + size // 2, w)\n",
        "    y2 = min(cy + size // 2, h)\n",
        "\n",
        "    eye = image[y1:y2, x1:x2]\n",
        "\n",
        "    if eye.size == 0:\n",
        "        return None\n",
        "\n",
        "    return cv2.resize(eye, (TARGET_SIZE, TARGET_SIZE))\n",
        "\n",
        "\n",
        "# ----------- DEMO ON ONE IMAGE ----------------\n",
        "image_path = \"001_glasses_nonsleepyCombination_000000_0.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "with mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5\n",
        ") as face_mesh:\n",
        "\n",
        "    results = face_mesh.process(image_rgb)\n",
        "\n",
        "    if not results.multi_face_landmarks:\n",
        "        print(\"No face detected\")\n",
        "        exit()\n",
        "\n",
        "    landmarks = results.multi_face_landmarks[0].landmark\n",
        "\n",
        "    left_eye = crop_eye(image, landmarks, LEFT_EYE)\n",
        "    right_eye = crop_eye(image, landmarks, RIGHT_EYE)\n",
        "\n",
        "    if left_eye is not None:\n",
        "        cv2.imwrite(\"001_glasses_nonsleepyCombination_000000_0_lefteye.jpg\", left_eye)\n",
        "\n",
        "    if right_eye is not None:\n",
        "        cv2.imwrite(\"001_glasses_nonsleepyCombination_000000_0_righteye.jpg\", right_eye)\n",
        "\n",
        "print(\"Eye samples saved ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na1hN_aDPoj5",
        "outputId": "63cc14ac-c21e-47b4-dd5c-795e270c185f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ex.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.10 ex.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvpoyT0KPuvD",
        "outputId": "0fb940b7-e7f9-4d90-d175-abc27b1954b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "Eye samples saved ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file run.py\n",
        "\n",
        "import os\n",
        "os.environ.pop(\"MPLBACKEND\", None)\n",
        "os.environ[\"MPLBACKEND\"] = \"Agg\"\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Eye landmark indices (FaceMesh)\n",
        "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
        "\n",
        "TARGET_SIZE = 224\n",
        "MARGIN = 0.3  # adjust if needed\n",
        "\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "\n",
        "def crop_eye(image, landmarks, eye_indices):\n",
        "    h, w, _ = image.shape\n",
        "\n",
        "    pts = np.array([\n",
        "        [int(landmarks[i].x * w), int(landmarks[i].y * h)]\n",
        "        for i in eye_indices\n",
        "    ])\n",
        "\n",
        "    x, y, bw, bh = cv2.boundingRect(pts)\n",
        "\n",
        "    cx, cy = x + bw // 2, y + bh // 2\n",
        "    size = int(max(bw, bh) * (1 + MARGIN))\n",
        "\n",
        "    x1 = max(cx - size // 2, 0)\n",
        "    y1 = max(cy - size // 2, 0)\n",
        "    x2 = min(cx + size // 2, w)\n",
        "    y2 = min(cy + size // 2, h)\n",
        "\n",
        "    eye = image[y1:y2, x1:x2]\n",
        "\n",
        "    if eye.size == 0:\n",
        "        return None\n",
        "\n",
        "    return cv2.resize(eye, (TARGET_SIZE, TARGET_SIZE))\n",
        "\n",
        "\n",
        "def process_image(image_path, output_root, face_mesh):\n",
        "    image = cv2.imread(str(image_path))\n",
        "    if image is None:\n",
        "        return\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    results = face_mesh.process(image_rgb)\n",
        "\n",
        "    if not results.multi_face_landmarks:\n",
        "        return  # skip if no face\n",
        "\n",
        "    landmarks = results.multi_face_landmarks[0].landmark\n",
        "\n",
        "    left_eye = crop_eye(image, landmarks, LEFT_EYE)\n",
        "    right_eye = crop_eye(image, landmarks, RIGHT_EYE)\n",
        "\n",
        "    # Maintain folder structure\n",
        "    rel_path = image_path.relative_to(INPUT_ROOT)\n",
        "    save_folder = OUTPUT_ROOT / rel_path.parent\n",
        "    save_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    stem = image_path.stem\n",
        "\n",
        "    if left_eye is not None:\n",
        "        cv2.imwrite(str(save_folder / f\"{stem}_lefteye.jpg\"), left_eye)\n",
        "\n",
        "    if right_eye is not None:\n",
        "        cv2.imwrite(str(save_folder / f\"{stem}_righteye.jpg\"), right_eye)\n",
        "\n",
        "\n",
        "def process_dataset(input_root, output_root):\n",
        "    global INPUT_ROOT, OUTPUT_ROOT\n",
        "    INPUT_ROOT = Path(input_root)\n",
        "    OUTPUT_ROOT = Path(output_root)\n",
        "\n",
        "    with mp_face_mesh.FaceMesh(\n",
        "        static_image_mode=True,\n",
        "        refine_landmarks=True,\n",
        "        max_num_faces=1,\n",
        "        min_detection_confidence=0.5\n",
        "    ) as face_mesh:\n",
        "\n",
        "        image_paths = list(INPUT_ROOT.rglob(\"*.jpg\"))\n",
        "\n",
        "        for img_path in tqdm(image_paths):\n",
        "            process_image(img_path, OUTPUT_ROOT, face_mesh)\n",
        "\n",
        "\n",
        "# ---------------- RUN ----------------\n",
        "\n",
        "INPUT_IMAGES = \"/root/.cache/kagglehub/datasets/manith04/ddd-processed-1-training-frames-type-1/versions/1\"\n",
        "OUTPUT_EYES = \"/content/processed_training_1_eyes\"\n",
        "\n",
        "process_dataset(INPUT_IMAGES, OUTPUT_EYES)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0SfQL-zRddy",
        "outputId": "59daf3c3-f236-4cde-8256-fc33e68d308b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing run.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.10 run.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npo4tD90Rg_P",
        "outputId": "f9b0d715-f30f-4591-c599-787fcae4f667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "100% 395691/395691 [1:21:03<00:00, 81.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /root/.cache/kagglehub/datasets/manith04/ddd-processed-1-training-frames-type-1/versions/1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYj0kFvxYBE7",
        "outputId": "d0e01564-fb7b-488b-c24a-90972881305b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "001  002  005  006  008  009  012  013\t015  020\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}